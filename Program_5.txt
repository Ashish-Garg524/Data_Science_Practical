                                   Program-5

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load and preprocess the data
data = pd.read_csv("student_performance.csv")

# Plot the feature importances using Seaborn
# Assuming you've already trained the Random Forest model and named it 'random_forest'
feature_importances = random_forest.feature_importances_
feature_names = data.columns.drop("student_performance")

feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
plt.title('Feature Importances')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

from sklearn.model_selection import GridSearchCV

# Assuming X_train, X_test, y_train, y_test are already prepared

# Create a Random Forest classifier
from sklearn.ensemble import RandomForestClassifier

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Instantiate the grid search
grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5, n_jobs=-1)

# Fit the grid search to the data
grid_search.fit(X_train, y_train)

# Get the best parameters
best_params = grid_search.best_params_

# Instantiate a Random Forest classifier with the best parameters
best_random_forest = RandomForestClassifier(**best_params)
best_random_forest.fit(X_train, y_train)

from sklearn.metrics import classification_report, confusion_matrix

# Make predictions
y_pred = best_random_forest.predict(X_test)

# Print classification report and confusion matrix
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
